{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reportedcity</th>\n",
       "      <th>dateofloss</th>\n",
       "      <th>elevationdifference</th>\n",
       "      <th>floodzone</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>numberoffloorsintheinsuredbuilding</th>\n",
       "      <th>occupancytype</th>\n",
       "      <th>originalconstructiondate</th>\n",
       "      <th>amountpaidonbuildingclaim</th>\n",
       "      <th>state</th>\n",
       "      <th>reportedzipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OCEANSIDE</td>\n",
       "      <td>1998-02-07</td>\n",
       "      <td>999.0</td>\n",
       "      <td>X</td>\n",
       "      <td>33.2</td>\n",
       "      <td>-117.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1963-01-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>CA</td>\n",
       "      <td>92056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEW ORLEANS</td>\n",
       "      <td>2005-08-29</td>\n",
       "      <td>999.0</td>\n",
       "      <td>X</td>\n",
       "      <td>29.9</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1967-07-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>LA</td>\n",
       "      <td>70131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NAVARRE</td>\n",
       "      <td>1998-09-28</td>\n",
       "      <td>999.0</td>\n",
       "      <td>X</td>\n",
       "      <td>30.4</td>\n",
       "      <td>-86.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1972-01-01</td>\n",
       "      <td>8813.21</td>\n",
       "      <td>FL</td>\n",
       "      <td>32566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BEAUFORT</td>\n",
       "      <td>1994-10-07</td>\n",
       "      <td>999.0</td>\n",
       "      <td>X</td>\n",
       "      <td>32.4</td>\n",
       "      <td>-80.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1960-01-01</td>\n",
       "      <td>2906.00</td>\n",
       "      <td>SC</td>\n",
       "      <td>29902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MELBOURNE</td>\n",
       "      <td>1996-03-11</td>\n",
       "      <td>999.0</td>\n",
       "      <td>X</td>\n",
       "      <td>28.3</td>\n",
       "      <td>-80.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1988-01-01</td>\n",
       "      <td>3875.53</td>\n",
       "      <td>FL</td>\n",
       "      <td>32940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reportedcity  dateofloss  elevationdifference floodzone  latitude  \\\n",
       "0    OCEANSIDE  1998-02-07                999.0         X      33.2   \n",
       "1  NEW ORLEANS  2005-08-29                999.0         X      29.9   \n",
       "2      NAVARRE  1998-09-28                999.0         X      30.4   \n",
       "3     BEAUFORT  1994-10-07                999.0         X      32.4   \n",
       "4    MELBOURNE  1996-03-11                999.0         X      28.3   \n",
       "\n",
       "   longitude  numberoffloorsintheinsuredbuilding  occupancytype  \\\n",
       "0     -117.3                                 4.0            1.0   \n",
       "1      -90.0                                 2.0            1.0   \n",
       "2      -86.9                                 1.0            1.0   \n",
       "3      -80.7                                 2.0            1.0   \n",
       "4      -80.7                                 1.0            1.0   \n",
       "\n",
       "  originalconstructiondate  amountpaidonbuildingclaim state reportedzipcode  \n",
       "0               1963-01-01                       0.00    CA           92056  \n",
       "1               1967-07-01                       0.00    LA           70131  \n",
       "2               1972-01-01                    8813.21    FL           32566  \n",
       "3               1960-01-01                    2906.00    SC           29902  \n",
       "4               1988-01-01                    3875.53    FL           32940  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "#import tensorflow as tf\n",
    "\n",
    "# Import our input dataset\n",
    "#data = Path('./Data/FIMA_cleaned.csv')\n",
    "data = Path('./Data/FEMA_Clean14.csv')\n",
    "FEMA_df = pd.read_csv(data)\n",
    "FEMA_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payouts <0 :  475808\n",
      "Payouts >500000 :  669\n"
     ]
    }
   ],
   "source": [
    "#FEMA_df[FEMA_df < 0].count()\n",
    "\n",
    "# Get a bool series representing which row satisfies the condition i.e. True for\n",
    "# row in which value of 'Age' column is more than 30\n",
    "NoPayout = FEMA_df.apply(lambda x: True if x['amountpaidonbuildingclaim'] <= 0 else False , axis=1)\n",
    "LargePayout = FEMA_df.apply(lambda x: True if x['amountpaidonbuildingclaim'] > 500000 else False , axis=1)\n",
    " \n",
    "# Count number of True in series\n",
    "NoPayoutRows = len(NoPayout[NoPayout == True].index)\n",
    "LargePayoutRows = len(LargePayout[LargePayout == True].index)\n",
    " \n",
    "print('Payouts <0 : ', NoPayoutRows)\n",
    "print('Payouts >500000 : ', LargePayoutRows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = FEMA_df.copy()\n",
    "df = df.drop(\"reportedzipcode\", axis=1)\n",
    "#df = df.drop(\"state\", axis=1)\n",
    "#df = df.drop(\"floodzone\", axis=1)\n",
    "df = df.drop(\"dateofloss\", axis=1)\n",
    "df = df.drop(\"originalconstructiondate\", axis=1)\n",
    "df = df.drop(\"reportedcity\", axis=1)\n",
    "df = df.drop(\"latitude\", axis=1)\n",
    "df = df.drop(\"longitude\", axis=1)\n",
    "FEMA_encoded = pd.get_dummies(df, columns=[\"state\", \"floodzone\"])#, \"reportedzipcode\"])\n",
    "\n",
    "\n",
    "y =FEMA_encoded.copy()\n",
    "X = FEMA_encoded.copy()\n",
    "X = X.drop(\"amountpaidonbuildingclaim\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.utils.multiclass' has no attribute 'typeb_of_target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-61932eefcfa3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulticlass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulticlass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypeb_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulticlass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sklearn.utils.multiclass' has no attribute 'typeb_of_target'"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "#X_train_encoded = lab_enc.fit_transform(X_train)\n",
    "\n",
    "print(utils.multiclass.type_of_target(y_train))\n",
    "print(utils.multiclass.typeb_of_target(X_train))\n",
    "print(utils.multiclass.type_of_target(X_train_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the X and y into X_train, X_test, y_train, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y['amountpaidonbuildingclaim'],\n",
    "                                                   random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-ab1b00ae5c5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#random forest, neural networks with linear regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m   1527\u001b[0m                          accept_large_sparse=solver != 'liblinear')\n\u001b[1;32m-> 1528\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1530\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# Train the Classifier\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "#random forest, neural networks with linear regression\n",
    "model = LogisticRegression() \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elevationdifference multiclass\n",
      "numberoffloorsintheinsuredbuilding multiclass\n",
      "occupancytype multiclass\n",
      "state_AK binary\n",
      "state_AL binary\n",
      "state_AR binary\n",
      "state_AS binary\n",
      "state_AZ binary\n",
      "state_CA binary\n",
      "state_CO binary\n",
      "state_CT binary\n",
      "state_DC binary\n",
      "state_DE binary\n",
      "state_FL binary\n",
      "state_GA binary\n",
      "state_GU binary\n",
      "state_HI binary\n",
      "state_IA binary\n",
      "state_ID binary\n",
      "state_IL binary\n",
      "state_IN binary\n",
      "state_KS binary\n",
      "state_KY binary\n",
      "state_LA binary\n",
      "state_MA binary\n",
      "state_MD binary\n",
      "state_ME binary\n",
      "state_MI binary\n",
      "state_MN binary\n",
      "state_MO binary\n",
      "state_MS binary\n",
      "state_MT binary\n",
      "state_NC binary\n",
      "state_ND binary\n",
      "state_NE binary\n",
      "state_NH binary\n",
      "state_NJ binary\n",
      "state_NM binary\n",
      "state_NV binary\n",
      "state_NY binary\n",
      "state_OH binary\n",
      "state_OK binary\n",
      "state_OR binary\n",
      "state_PA binary\n",
      "state_PR binary\n",
      "state_RI binary\n",
      "state_SC binary\n",
      "state_SD binary\n",
      "state_TN binary\n",
      "state_TX binary\n",
      "state_UT binary\n",
      "state_VA binary\n",
      "state_VI binary\n",
      "state_VT binary\n",
      "state_WA binary\n",
      "state_WI binary\n",
      "state_WV binary\n",
      "state_WY binary\n",
      "floodzone_000 binary\n",
      "floodzone_A binary\n",
      "floodzone_A-- binary\n",
      "floodzone_A00 binary\n",
      "floodzone_A01 binary\n",
      "floodzone_A02 binary\n",
      "floodzone_A03 binary\n",
      "floodzone_A04 binary\n",
      "floodzone_A05 binary\n",
      "floodzone_A06 binary\n",
      "floodzone_A07 binary\n",
      "floodzone_A08 binary\n",
      "floodzone_A09 binary\n",
      "floodzone_A0B binary\n",
      "floodzone_A10 binary\n",
      "floodzone_A11 binary\n",
      "floodzone_A12 binary\n",
      "floodzone_A13 binary\n",
      "floodzone_A14 binary\n",
      "floodzone_A15 binary\n",
      "floodzone_A16 binary\n",
      "floodzone_A17 binary\n",
      "floodzone_A18 binary\n",
      "floodzone_A19 binary\n",
      "floodzone_A20 binary\n",
      "floodzone_A21 binary\n",
      "floodzone_A22 binary\n",
      "floodzone_A23 binary\n",
      "floodzone_A24 binary\n",
      "floodzone_A25 binary\n",
      "floodzone_A26 binary\n",
      "floodzone_A27 binary\n",
      "floodzone_A28 binary\n",
      "floodzone_A29 binary\n",
      "floodzone_A30 binary\n",
      "floodzone_A4 binary\n",
      "floodzone_A99 binary\n",
      "floodzone_AA binary\n",
      "floodzone_AE binary\n",
      "floodzone_AH binary\n",
      "floodzone_AHB binary\n",
      "floodzone_AO binary\n",
      "floodzone_AO5 binary\n",
      "floodzone_AOB binary\n",
      "floodzone_AR binary\n",
      "floodzone_B binary\n",
      "floodzone_C binary\n",
      "floodzone_D binary\n",
      "floodzone_OOO binary\n",
      "floodzone_V binary\n",
      "floodzone_V01 binary\n",
      "floodzone_V02 binary\n",
      "floodzone_V03 binary\n",
      "floodzone_V04 binary\n",
      "floodzone_V05 binary\n",
      "floodzone_V06 binary\n",
      "floodzone_V07 binary\n",
      "floodzone_V08 binary\n",
      "floodzone_V09 binary\n",
      "floodzone_V10 binary\n",
      "floodzone_V11 binary\n",
      "floodzone_V12 binary\n",
      "floodzone_V13 binary\n",
      "floodzone_V14 binary\n",
      "floodzone_V15 binary\n",
      "floodzone_V16 binary\n",
      "floodzone_V17 binary\n",
      "floodzone_V18 binary\n",
      "floodzone_V19 binary\n",
      "floodzone_V20 binary\n",
      "floodzone_V21 binary\n",
      "floodzone_V22 binary\n",
      "floodzone_V23 binary\n",
      "floodzone_V24 binary\n",
      "floodzone_V27 binary\n",
      "floodzone_V30 binary\n",
      "floodzone_VE binary\n",
      "floodzone_X binary\n"
     ]
    }
   ],
   "source": [
    "for i in X_train.columns:\n",
    "    print(i, utils.multiclass.type_of_target(X_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.dtypes\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Classifier\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#random forest, neural networks with linear regression\n",
    "model = LinearRegression() \n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16123, 12)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structureType = FEMA_df.groupby('occupancytype')\n",
    "\n",
    "businessProperties = structureType.get_group(6)\n",
    "\n",
    "businessProperties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Payouts <0 : 475808\n",
      "Payouts <0 for business properties :  4715\n",
      "Total invalid elevations :  1403326\n"
     ]
    }
   ],
   "source": [
    "InvalidElevation = FEMA_df.apply(lambda x: True if x['elevationdifference'] ==999.0 else False , axis=1)\n",
    "noBuisPayout = businessProperties.apply(lambda x: True if x['amountpaidonbuildingclaim'] <=0 else False , axis=1)\n",
    " \n",
    "# Count number of True in series\n",
    "InvalidElevationRows = len(InvalidElevation[InvalidElevation == True].index)\n",
    "noBuisPayoutRows = len(noBuisPayout[noBuisPayout == True].index)\n",
    " \n",
    "print('Total Payouts <0 : 475808')\n",
    "print('Payouts <0 for business properties : ', noBuisPayoutRows)\n",
    "print('Total invalid elevations : ', InvalidElevationRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = FEMA_df.copy()\n",
    "df = df.drop(\"reportedzipcode\", axis=1)\n",
    "#df = df.drop(\"state\", axis=1)\n",
    "#df = df.drop(\"floodzone\", axis=1)\n",
    "df = df.drop(\"dateofloss\", axis=1)\n",
    "df = df.drop(\"originalconstructiondate\", axis=1)\n",
    "df = df.drop(\"reportedcity\", axis=1)\n",
    "df = df.drop(\"latitude\", axis=1)\n",
    "df = df.drop(\"longitude\", axis=1)\n",
    "FEMA_encoded = pd.get_dummies(df, columns=[\"state\", \"floodzone\"])#, \"reportedzipcode\"])\n",
    "\n",
    "\n",
    "y =FEMA_encoded.copy()\n",
    "X = FEMA_encoded.copy()\n",
    "X = X.drop(\"amountpaidonbuildingclaim\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "FloodZones = FEMA_df.groupby('floodzone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "FloodZone_X = y.groupby('floodzone_X')\n",
    "\n",
    "FloodZone_X = FloodZone_X.get_group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =FloodZone_X.copy()\n",
    "X = FloodZone_X.copy()\n",
    "X = X.drop(\"amountpaidonbuildingclaim\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the X and y into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y['floodzone_X'],\n",
    "                                                   random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-f44724590846>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1556\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[0;32m   1557\u001b[0m                              \u001b[1;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1558\u001b[1;33m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[0;32m   1559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1560\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
